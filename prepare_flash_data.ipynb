{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_file_path = \"/home/jony/Git/GAN-N-Net/datasets/new_raw_data/site4_28_classes_ready2go.pkl\"\n",
    "pkl_file_path = \"/home/jony/git/GAN-N-Net/datasets/new_raw_data/site4_28_classes_ready2go.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(pkl_file_path)\n",
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "def read_pickle_in_chunks(file_path, chunk_size=10):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                chunk = dill.load(f)\n",
    "                yield pd.DataFrame(chunk)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "# Usage\n",
    "file_path = 'large_pickle_file.pkl'\n",
    "chunk_size = 1000\n",
    "\n",
    "for i, chunk in enumerate(read_pickle_in_chunks(file_path, chunk_size)):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_port_TDL(row, min_delta=1e-5):\n",
    "    to_return = []\n",
    "\n",
    "    measures = np.array(row['udps.protocol_header_fields_enh'][:, 1])\n",
    "    # sizes = (measures - measures.min()) / (measures.max() - measures.min())\n",
    "    sizes = measures #  (maybe I can change all zeroes to 1. so it will be different than no data)\n",
    "    directions = [0]*len(measures)\n",
    "    for el_i, el in enumerate(row['udps.protocol_header_fields_enh'][:, 0]): # enumerate(np.array(hlp_protocol_header_fields_enh[:,0])): # enumerate(row['udps.protocol_header_fields_enh'][:, 0]):\n",
    "        if el != 0:\n",
    "            directions[el_i] = 1\n",
    "            # normalized_measures[el_i] *= -1\n",
    "    measures = np.array(row['udps.protocol_header_fields_enh'][:, 2])\n",
    "    measures = measures / 1000\n",
    "    times = [0] * len(measures)\n",
    "    for i in range(1, len(times)):\n",
    "        times[i] = times[i-1] + max(measures[i], min_delta)\n",
    "    # if measures.max() != measures.min():    # we want to avoid 0/0\n",
    "    #     times = (measures - measures.min()) / (measures.max() - measures.min())\n",
    "\n",
    "    for item in zip(times, directions, sizes):\n",
    "        to_return.append(list(item))\n",
    "\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-14_v7_24_05_24_04_48_10_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-02_v7_24_05_24_06_25_50_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-16_v7_24_05_24_01_32_37_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-23_v7_24_05_23_14_36_53_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-07_v7_24_05_23_17_54_02_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-06_v7_24_05_23_15_42_14_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-23_v7_24_05_24_08_38_09_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-11_v7_24_05_24_03_10_29_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-17_v7_24_05_24_04_48_11_600_n8_WF.csv', '/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-04_v7_24_05_24_00_59_55_600_n8_WF.csv']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/\"\n",
    "dest_dir = 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs_ready_tdl'\n",
    "# get list of all files in data_dir\n",
    "files = glob.glob(data_dir + \"*.csv\")\n",
    "print(files[:10])\n",
    "files = files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tcp1-vmsp-p-14_v7_24_05_24_04_48_10_600_n8_WF.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# loop through each CSV file and read it into a DataFrame\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['filename'] = file.split('/')[-1]\n",
    "    df['packet_number'] = df['udps.protocol_header_fields_enh'].str.count('\\n')\n",
    "    # this raw convert the nfstream plugin output from string to list of lists - for now it is crashing\n",
    "    df['udps.protocol_header_fields_enh'] = df['udps.protocol_header_fields_enh'].apply(lambda x: np.array([list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()]))\n",
    "    df[\"tdl\"] = df.apply(build_port_TDL, axis=1)\n",
    "    df.to_csv(os.path.join(dest_dir, file.split('/')[-1]), index=False)\n",
    "    # this raw convert the nfstream plugin output from string to list of lists - for now it is crashing\n",
    "    # df['splited'] = df['udps.protocol_header_fields_enh'].str.replace('[', '').str.replace(']', '').apply(lambda x: [list(map(int, row.split())) for row in x.split('\\n')])\n",
    "    # dfs.append(df)\n",
    "\n",
    "# concatenate all DataFrames into a single one\n",
    "# big_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_application_types\n",
       "TikTok                  86\n",
       "Youtube_YoutubeMusic    53\n",
       "Instagram_Threads        4\n",
       "FacebookMessenger        2\n",
       "Facebook                 1\n",
       "Yahoo                    1\n",
       "XVideos                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.new_application_types.value_counts()\n",
    "df[df.new_application_types!=\"other\"].new_application_types.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'colums'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13743/1624352445.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_tdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tdl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_tdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"new_application_types\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"new_application_types\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_tdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ganet/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'colums'"
     ]
    }
   ],
   "source": [
    "df_tdl = df['tdl'].apply(lambda x: pd.DataFrame(x, columns=['col1', 'col2', 'col3']))\n",
    "df_tdl[\"new_application_types\"] = df[\"new_application_types\"]\n",
    "df_tdl.colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdl_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all can be found in EIMTC git repo (ask amit and chen)\n",
    "# udps.protocol_header_fields_enh - nfstream plugin that contains:\n",
    "    # Dirrection: 0 - source to destination, 1 - destination to source\n",
    "    # payload_size: not include headers\n",
    "    # delta_time: time from previus packet\n",
    "    # scapy_tcp: I don't kknow what it is\n",
    "    # len(scapy_tcp.options): I don't kknow what it is\n",
    "    # scapy_ip.ttl: ttl value....\n",
    "\n",
    "# These are the labels coulumns:\n",
    "    # new_application_types\n",
    "    # new_traffic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.split())) for row in x.strip().split('\\n')])\n",
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip('[]').split())) for row in x.strip().split('\\n') if row.strip()])\n",
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()])\n",
    "\n",
    "# big_df.iloc[:1000]['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'bidirectional_first_seen_ms', 'new_application_types',\n",
       "       'new_stnn', 'udps.packets_raw_sizes', 'udps.protocol_header_fields_enh',\n",
       "       'udps.simple_tig_adj', 'udps.simple_tig_features',\n",
       "       'application_category_name', 'udps.stnn_image', 'udps.OTT',\n",
       "       'udps.flowType', 'new_traffic_types', 'application_name',\n",
       "       'udps.n_bytes', 'filename', 'packet_number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: np.array([list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()]))\n",
    "# big_df['splited'] = big_df.apply(from_protocol_header_fields_enh_saved_to_ndarray, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df[\"tdl\"] = big_df.apply(build_port_TDL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.57275999999989, 1, 1232],\n",
       " [5.572769999999889, 1, 1232],\n",
       " [5.572779999999889, 1, 1232],\n",
       " [5.572789999999888, 1, 1232],\n",
       " [5.572799999999888, 1, 1232],\n",
       " [5.574799999999888, 1, 1232],\n",
       " [5.5748099999998875, 1, 1232],\n",
       " [5.574819999999887, 1, 1232],\n",
       " [5.574829999999887, 1, 1232],\n",
       " [5.574839999999886, 1, 1232],\n",
       " [5.5778399999998864, 1, 1232],\n",
       " [5.577849999999886, 1, 1232],\n",
       " [5.577859999999886, 1, 1232],\n",
       " [5.577869999999885, 1, 1232],\n",
       " [5.577879999999885, 1, 1232],\n",
       " [5.579879999999885, 1, 1232],\n",
       " [5.579889999999884, 1, 1232],\n",
       " [5.579899999999884, 1, 1232],\n",
       " [5.579909999999884, 1, 1232],\n",
       " [5.579919999999883, 1, 1232]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.tdl.iloc[0][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

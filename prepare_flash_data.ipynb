{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tcbench as tcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_port_TDL(row, min_delta=1e-5):\n",
    "    to_return = []\n",
    "\n",
    "    measures = np.array(row['udps.protocol_header_fields_enh'][:, 1])\n",
    "    # sizes = (measures - measures.min()) / (measures.max() - measures.min())\n",
    "    sizes = measures #  (maybe I can change all zeroes to 1. so it will be different than no data)\n",
    "    directions = [0]*len(measures)\n",
    "    for el_i, el in enumerate(row['udps.protocol_header_fields_enh'][:, 0]): # enumerate(np.array(hlp_protocol_header_fields_enh[:,0])): # enumerate(row['udps.protocol_header_fields_enh'][:, 0]):\n",
    "        if el != 0:\n",
    "            directions[el_i] = 1\n",
    "            # normalized_measures[el_i] *= -1\n",
    "    measures = np.array(row['udps.protocol_header_fields_enh'][:, 2])\n",
    "    measures = measures / 1000\n",
    "    times = [0] * len(measures)\n",
    "    for i in range(1, len(times)):\n",
    "        times[i] = times[i-1] + max(measures[i], min_delta)\n",
    "    # if measures.max() != measures.min():    # we want to avoid 0/0\n",
    "    #     times = (measures - measures.min()) / (measures.max() - measures.min())\n",
    "\n",
    "    for item in zip(times, directions, sizes):\n",
    "        to_return.append(list(item))\n",
    "\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-10_v7_24_05_23_15_42_14_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-06_v7_24_05_23_19_32_08_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-16_v7_24_05_23_18_59_23_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-18_v7_24_05_23_17_21_23_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-01_v7_24_05_24_05_20_44_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-08_v7_24_05_23_16_15_36_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-04_v7_24_05_24_02_37_53_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-19_v7_24_05_23_23_22_00_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-07_v7_24_05_24_04_48_11_600_n8_WF.csv', 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/tcp1-vmsp-p-17_v7_24_05_23_17_54_02_600_n8_WF.csv']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/jony/git/GAN-N-Net/datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/\"\n",
    "data_dir = \"datasets/new_raw_data/site5_1500_packets_al_to_share/csvs/\"\n",
    "dest_dir = 'datasets/new_raw_data/site5_1500_packets_al_to_share/csvs_ready_tdl'\n",
    "# get list of all files in data_dir\n",
    "files = glob.glob(data_dir + \"*.csv\")\n",
    "print(files[:10])\n",
    "# files = files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tcp1-vmsp-p-14_v7_24_05_24_04_48_10_600_n8_WF.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# loop through each CSV file and read it into a DataFrame\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['filename'] = file.split('/')[-1]\n",
    "    # df['packet_number'] = df['udps.protocol_header_fields_enh'].str.count('\\n')\n",
    "    # this raw convert the nfstream plugin output from string to list of lists - for now it is crashing\n",
    "    # df['udps.protocol_header_fields_enh'] = df['udps.protocol_header_fields_enh'].apply(lambda x: np.array([list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()]))\n",
    "    # df[\"tdl\"] = df.apply(build_port_TDL, axis=1)\n",
    "    # df.to_csv(os.path.join(dest_dir, file.split('/')[-1]), index=False)\n",
    "    # this raw convert the nfstream plugin output from string to list of lists - for now it is crashing\n",
    "    # df['splited'] = df['udps.protocol_header_fields_enh'].str.replace('[', '').str.replace(']', '').apply(lambda x: [list(map(int, row.split())) for row in x.split('\\n')])\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate all DataFrames into a single one\n",
    "big_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_application_types\n",
       "other                   55499\n",
       "TikTok                  26525\n",
       "Youtube_YoutubeMusic    13996\n",
       "Roblox                   2623\n",
       "Yahoo                    1583\n",
       "Instagram_Threads        1062\n",
       "FacebookMessenger         624\n",
       "Twitter                   589\n",
       "CDNs                      555\n",
       "AppleMusic                494\n",
       "Facebook                  449\n",
       "NBC                       390\n",
       "NETFLIX                   322\n",
       "Whatsapp                  298\n",
       "Pornhub                   287\n",
       "RedTube                   167\n",
       "Cloudfront                161\n",
       "XVideos                   123\n",
       "GoogleMaps                123\n",
       "ToonGoggles                97\n",
       "Snapchat                   35\n",
       "DoppioCDN                  31\n",
       "FoxSports                  22\n",
       "Spotify                    21\n",
       "soundcloud                 18\n",
       "Amazon                     17\n",
       "Discord                    17\n",
       "XHamster                   14\n",
       "GameStores                  2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.new_application_types.value_counts()\n",
    "# df[df.new_application_types!=\"other\"].new_application_types.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'colums'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13743/1624352445.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_tdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tdl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_tdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"new_application_types\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"new_application_types\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_tdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ganet/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'colums'"
     ]
    }
   ],
   "source": [
    "df_tdl = df['tdl'].apply(lambda x: pd.DataFrame(x, columns=['col1', 'col2', 'col3']))\n",
    "df_tdl[\"new_application_types\"] = df[\"new_application_types\"]\n",
    "df_tdl.colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdl_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all can be found in EIMTC git repo (ask amit and chen)\n",
    "# udps.protocol_header_fields_enh - nfstream plugin that contains:\n",
    "    # Dirrection: 0 - source to destination, 1 - destination to source\n",
    "    # payload_size: not include headers\n",
    "    # delta_time: time from previus packet\n",
    "    # scapy_tcp: I don't kknow what it is\n",
    "    # len(scapy_tcp.options): I don't kknow what it is\n",
    "    # scapy_ip.ttl: ttl value....\n",
    "\n",
    "# These are the labels coulumns:\n",
    "    # new_application_types\n",
    "    # new_traffic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.split())) for row in x.strip().split('\\n')])\n",
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip('[]').split())) for row in x.strip().split('\\n') if row.strip()])\n",
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()])\n",
    "\n",
    "# big_df.iloc[:1000]['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'bidirectional_first_seen_ms', 'new_application_types',\n",
       "       'new_stnn', 'udps.packets_raw_sizes', 'udps.protocol_header_fields_enh',\n",
       "       'udps.simple_tig_adj', 'udps.simple_tig_features',\n",
       "       'application_category_name', 'udps.stnn_image', 'udps.OTT',\n",
       "       'udps.flowType', 'new_traffic_types', 'application_name',\n",
       "       'udps.n_bytes', 'filename', 'packet_number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: np.array([list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()]))\n",
    "# big_df['splited'] = big_df.apply(from_protocol_header_fields_enh_saved_to_ndarray, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df[\"tdl\"] = big_df.apply(build_port_TDL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.57275999999989, 1, 1232],\n",
       " [5.572769999999889, 1, 1232],\n",
       " [5.572779999999889, 1, 1232],\n",
       " [5.572789999999888, 1, 1232],\n",
       " [5.572799999999888, 1, 1232],\n",
       " [5.574799999999888, 1, 1232],\n",
       " [5.5748099999998875, 1, 1232],\n",
       " [5.574819999999887, 1, 1232],\n",
       " [5.574829999999887, 1, 1232],\n",
       " [5.574839999999886, 1, 1232],\n",
       " [5.5778399999998864, 1, 1232],\n",
       " [5.577849999999886, 1, 1232],\n",
       " [5.577859999999886, 1, 1232],\n",
       " [5.577869999999885, 1, 1232],\n",
       " [5.577879999999885, 1, 1232],\n",
       " [5.579879999999885, 1, 1232],\n",
       " [5.579889999999884, 1, 1232],\n",
       " [5.579899999999884, 1, 1232],\n",
       " [5.579909999999884, 1, 1232],\n",
       " [5.579919999999883, 1, 1232]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.tdl.iloc[0][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

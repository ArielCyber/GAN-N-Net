{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 21:49:20.217005: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 21:49:20.217226: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 21:49:20.368116: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 21:49:20.598576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 21:49:21.828697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tools import load_data\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUIC Berkeley (quic text)\n",
    "# QUIC Paris-Est Cr√©teil(quic_pcaps)\n",
    "data_dirs = ['/home/jony/Git/GAN-N-Net/datasets/mini_flowpic_flash_clean/',\n",
    "            '/home/jony/Git/GAN-N-Net/datasets/mini_flowpic_quic_text/',\n",
    "            '/home/jony/Git/GAN-N-Net/datasets/mini_flowpic_quic_pcaps/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jony/Git/GAN-N-Net/datasets/mini_flowpic_flash_clean/\n",
      "working on: csvs_instagram.npy\n",
      "(46, 32, 32)\n",
      "working on: csvs_facebook.npy\n",
      "(320, 32, 32)\n",
      "working on: csvs_tiktok.npy\n",
      "(150, 32, 32)\n",
      "working on: csvs_youtube.npy\n",
      "(736, 32, 32)\n",
      "(1252, 32, 32)\n",
      "(1252,)\n",
      "(array([0., 1., 2., 3.]), array([ 46, 320, 150, 736]))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/jony/Git/GAN-N-Net/datasets/mini_flowpic_quic_text/\n",
      "working on: class_Google_Music.npy\n",
      "(592, 32, 32)\n",
      "working on: class_Google_Search.npy\n",
      "(1915, 32, 32)\n",
      "working on: class_Google_Doc.npy\n",
      "(8003, 32, 32)\n",
      "working on: class_Youtube.npy\n",
      "(3521, 32, 32)\n",
      "working on: quic_text.zip\n",
      "working on: class_Google_Drive.npy\n",
      "(2457, 32, 32)\n",
      "(16488, 32, 32)\n",
      "(16488,)\n",
      "(array([0., 1., 2., 3., 4.]), array([ 592, 1915, 8003, 3521, 2457]))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/jony/Git/GAN-N-Net/datasets/mini_flowpic_quic_pcaps/\n",
      "working on: first_Google_PlayMusic.npy\n",
      "(490, 32, 32)\n",
      "working on: first_YouTube.npy\n",
      "(1152, 32, 32)\n",
      "working on: first_GoogleHangout_Chat.npy\n",
      "(1106, 32, 32)\n",
      "working on: first_GoogleHangout_VoIP.npy\n",
      "(6779, 32, 32)\n",
      "(9527, 32, 32)\n",
      "(9527,)\n",
      "(array([0., 1., 2., 3.]), array([ 490, 1152, 1106, 6779]))\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_dir in data_dirs:    \n",
    "    files = glob.glob(data_dir + \"*\")\n",
    "    CLASS_NUM = len(files)\n",
    "\n",
    "\n",
    "    # GAN random input vector size\n",
    "    latent_dim = 32*32*3\n",
    "    data = []\n",
    "    labels = []\n",
    "    labelIndex = -1\n",
    "    print(data_dir)\n",
    "    for file in files:\n",
    "        print(f\"working on: {os.path.basename(file)}\")\n",
    "        if file.endswith('.npy'):\n",
    "            labelIndex += 1\n",
    "            dataForFile = load_data(file)\n",
    "            print(dataForFile.shape)\n",
    "            data.append(dataForFile)\n",
    "            labelsForFile = np.ones(dataForFile.__len__()) * labelIndex\n",
    "            labels.append(labelsForFile)\n",
    "\n",
    "\n",
    "    data = np.vstack(data)\n",
    "    labels = np.hstack(labels)\n",
    "    \n",
    "    print(data.shape)\n",
    "    print(labels.shape)\n",
    "    print(np.unique(labels,return_counts=True))\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                         0\n",
       "bidirectional_first_seen_ms                                            1716475693796\n",
       "new_application_types                                                          other\n",
       "new_stnn                           [ 0.0000000e+00  2.6720000e+03  3.3725000e+02 ...\n",
       "udps.packets_raw_sizes             [1454, 78, 1454, 78, 1454, 78, 1454, 100, 78, ...\n",
       "udps.protocol_header_fields_enh    [[    0  1388     0   868     3    58]\\n [    ...\n",
       "udps.simple_tig_adj                [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "udps.simple_tig_features           [[-1454.0], [78.0], [-1454.0], [78.0], [-1454....\n",
       "application_category_name                                              SocialNetwork\n",
       "udps.stnn_image                    [[0.0, 2672.0, 188.46875, 642.0958, 3.5761895,...\n",
       "udps.OTT                                                                    OtherOTT\n",
       "udps.flowType                                                                novideo\n",
       "new_traffic_types                                                              other\n",
       "application_name                                                         TLS.Twitter\n",
       "udps.n_bytes                       [23, 3, 3, 21, 205, 43, 159, 28, 119, 143, 64,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/home/jony/Git/GAN-N-Net/datasets/not_prosseesd_yet/site5_1500_packets_al_to_share/csvs/\"\n",
    "# get list of all files in data_dir\n",
    "files = glob.glob(data_dir + \"*.csv\")\n",
    "files[:10]\n",
    "df = pd.read_csv(files[0])\n",
    "df['udps.OTT'].unique()\n",
    "df.head()\n",
    "print(len(df.iloc[0][\"udps.packets_raw_sizes\"]))\n",
    "len(df.iloc[0][\"udps.n_bytes\"])\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# loop through each CSV file and read it into a DataFrame\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['filename'] = file.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate all DataFrames into a single one\n",
    "big_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df[\"len_packets_raw_sizes\"] = big_df[\"udps.packets_raw_sizes\"].apply(len)\n",
    "big_df[\"len_n_bytes\"] = big_df[\"udps.n_bytes\"].apply(len)\n",
    "big_df[\"len_packets_raw_sizes\"].describe()\n",
    "print(big_df[\"len_packets_raw_sizes\"].describe())\n",
    "print(big_df[\"len_n_bytes\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all can be found in EIMTC git repo (ask amit and chen)\n",
    "# udps.protocol_header_fields_enh - nfstream plugin that contains:\n",
    "    # Dirrection: 0 - source to destination, 1 - destination to source\n",
    "    # payload_size: not include headers\n",
    "    # delta_time: time from previus packet\n",
    "    # scapy_tcp: I don't kknow what it is\n",
    "    # len(scapy_tcp.options): I don't kknow what it is\n",
    "    # scapy_ip.ttl: ttl value....\n",
    "\n",
    "\n",
    "# type(big_df[\"udps.protocol_header_fields_enh\"].iloc[0])\n",
    "big_df[\"udps.protocol_header_fields_enh\"].iloc[0]\n",
    "\n",
    "# new_application_types, new_traffic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.split())) for row in x.strip().split('\\n')])\n",
    "# big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip('[]').split())) for row in x.strip().split('\\n') if row.strip()])\n",
    "big_df['splited'] = big_df['udps.protocol_header_fields_enh'].apply(lambda x: [list(map(int, row.strip().strip('[]').split())) for row in x.strip('[]').split('\\n') if row.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda x: [list(map(int, row.split())) for row in x.strip().split('\\n')]\n",
    "l = df['udps.protocol_header_fields_enh'].iloc[0].strip('[]').split('\\n')\n",
    "# print(df['udps.protocol_header_fields_enh'].iloc[0])\n",
    "list(map(int, l[0].strip('[]').split()))\n",
    "l[1].strip().strip('[]').split()\n",
    "# l[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
